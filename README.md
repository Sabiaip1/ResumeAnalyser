**README**

Анализатор резюме на основе нейросети

Описание проекта

Цель проекта — разработать нейросеть, которая сможет анализировать резюме кандидатов, выявлять основные ошибки и предлагать рекомендации по их исправлению. Это поможет соискателям улучшить свои резюме, а HR-специалистам — ускорить процесс отбора кандидатов.

Бизнес-юнит:

VK Education

Цель:

Создать сервис для автоматизированного анализа резюме, который будет выявлять типичные ошибки (например, отсутствие контактной информации, грамматические ошибки, отсутствие ключевых слов) и предлагать улучшения, такие как добавление релевантных навыков, оптимизация структуры или включение портфолио.
________________________________________
Текущий прогресс

Реализованные модули:
1.	Парсер вакансий с сайта HH.ru

o	Собирает данные по вакансиям из разных регионов (города-миллионники России).

o	Данные сохраняются в формате JSON для последующего анализа.

o	Скрипт позволяет получить информацию о вакансиях за последние 2–3 месяца.

2.	Анализатор резюме
   
o	Обработка файлов форматов DOCX и PDF.

o	Проверка языка резюме (русский).

o	Анализ орфографических и грамматических ошибок с помощью библиотеки language_tool_python.

o	Проверка ключевых слов, соответствующих требованиям вакансий.

o	Выявление хронологических ошибок (например, пробелов в датах опыта работы).

o	Генерация исправленного текста и оценка соответствия резюме требованиям (в процентах).

3.	Файл требований (JSON)
   
o	Содержит ключевые слова и навыки, которые требуются для проверки резюме.

o	JSON-файл легко настраивается для работы с разными вакансиями.
________________________________________
Используемые технологии и библиотеки

•	Парсер: requests, json, datetime

•	Обработка текста: language_tool_python, PyPDF2, python-docx, langdetect

•	Анализ данных: TfidfVectorizer, cosine_similarity

•	Поддержка файлов: Google Colab
________________________________________
Что реализовано:

•	Парсер вакансий с сайта HH.ru.

•	Модуль анализа резюме с проверкой ошибок и формированием рекомендаций.

•	Механизм загрузки и обработки требований из JSON.
________________________________________
Следующие шаги:

1.	Обучение модели:
   
o	На размеченных данных из собранных резюме и вакансий.

2.	Разработка пользовательского интерфейса:
   
o	Для загрузки резюме и получения анализа.

3.	Оптимизация нейросети:
   
o	Улучшение точности определения ошибок и выдачи рекомендаций.
________________________________________
Участники команды

•	Портной Жанна

•	Пашаева Сабина Идмановна

•	Пономарев Дмитрий Валентинович

•	Бирюков Владислав Михайлович
________________________________________
Как запустить
1.	Клонируйте репозиторий: 
2.	git clone <ссылка на репозиторий>
3.	Установите зависимости: 
4.	pip install -r requirements.txt
5.	Запустите анализатор резюме, загрузив файл через интерфейс Colab.
________________________________________
Мы готовы к промежуточной проверке проекта и ждем обратной связи!

